# -*- coding: utf-8 -*-
"""Data Processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1A0k8-Bzzbs0JFVddD40rj2EBDmXVYu-Y
"""

#imports
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
import torch.utils.data 
import torchvision.transforms as transforms
import torchvision.datasets as datasets
import matplotlib.pyplot as plt
from torch.utils.data.sampler import SubsetRandomSampler

#for reproducible results
torch.manual_seed(69)

"""We will assume that all input images come in a standard PIL image format"""

#Transformation 0: Convert to Tensor
transformation_0 = transforms.ToTensor()   #should make it a Tensor[3, X, Y] object

#Transformation 1: Cropping and Resizing
#for a square image, crop it directly to 224x224

transformation_1A = transforms.Resize(224)     #resizes so that shorter edge to 224 pixels
transformation_1B = transforms.CenterCrop(224)

#Transformation 2: Normalizations
#use the standard imagenet normalization values

transformation_2 = transformations.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])

#Transformation 3: White Balance
#transformation_3 = []

#Transformation 4: Random Rotation
transformation_4 = transforms.RandomRotation(-180)

#Transformation 5: Random Affine Transformation
transformation_5 = transforms.RandomAffine(-180)

transformations = transforms.Compose([transformation_1A, transformation_1B, transformation_2, transformation_3, transformation_4, transformation_5])

"""Now we create dataloader objects to feed into our networks/baseline models as necessary. Assume for now that the input data is all sorted together into images by class, allowing easy use of ImageFolder objects."""

image_data = datasets.ImageFolder(root="insert root folder here", transform=transformations)

#code to split the dataset into train, test, and validation data

#hyperparameters
train_ratio = 0.75
val_ratio = 0.15
test_ratio = 1 - train_ratio - val_ratio

batch_size = 64

#get indices to later throw into the random sampler
indices = list(range(len(data)))

#randomly split the data indices into train, test, and validation splits, with a fixed seed for reproducible results 
np.random.seed(100)
np.random.shuffle(indices)

train_split = round(len(data)*train_ratio)
val_split = train_split + round(len(data)*val_ratio)
test_split = val_split + round(len(data)*test_ratio)

#now split up the dataset itself
train_indices = indices[:train_split]
val_indices = indices[train_split:val_split]
test_indices = indices[val_split:]

#create the SubsetRandomSamplers
train_sampler = SubsetRandomSampler(train_indices)
val_sampler = SubsetRandomSampler(val_indices)
test_sampler = SubsetRandomSampler(test_indices)

#create DataLoader objects to be used in training
train_loader = torch.utils.data.DataLoader(dataset=data, shuffle=False, batch_size=batch_size, sampler=train_sampler, num_workers=2)
val_loader = torch.utils.data.DataLoader(dataset=data, shuffle=False, batch_size=batch_size, sampler=val_sampler, num_workers=2)
test_loader = torch.utils.data.DataLoader(dataset=data, shuffle=False, batch_size=batch_size, sampler=test_sampler, num_workers=2)